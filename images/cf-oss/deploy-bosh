#!/bin/bash
set -euo pipefail

export BOSH_DIRECTOR_IP="10.245.0.2"
export DIRECTOR_DIR=/var/vcap/director
mkdir -p "${DIRECTOR_DIR}"

exec 1> >(tee -i "${DIRECTOR_DIR}/deploy.log")
exec 2>&1

if [ -S /var/vcap/gdn.socket ]; then
  bosh int /var/vcap/cache/director.yml -o /var/vcap/use_gdn_unix_socket.yml > "${DIRECTOR_DIR}/director.yml"
else
  cp /var/vcap/cache/director.yml "${DIRECTOR_DIR}"
fi

bosh --tty create-env \
  "${DIRECTOR_DIR}/director.yml" \
  --vars-store="${DIRECTOR_DIR}/creds.yml" \
  --state="${DIRECTOR_DIR}/state.json"

bosh int "${DIRECTOR_DIR}/creds.yml" \
  --path /director_ssl/ca > "${DIRECTOR_DIR}/ca.crt"

bosh int "${DIRECTOR_DIR}/creds.yml" \
  --path /jumpbox_ssh/private_key > "${DIRECTOR_DIR}/jumpbox.key"

cat <<EOF > "${DIRECTOR_DIR}/env"
export BOSH_ENVIRONMENT="${BOSH_DIRECTOR_IP}"
export BOSH_CLIENT=admin
export BOSH_CLIENT_SECRET=$(bosh int "${DIRECTOR_DIR}/creds.yml" --path /admin_password)
export BOSH_CA_CERT="$(cat ${DIRECTOR_DIR}/ca.crt)"
EOF

source "${DIRECTOR_DIR}/env"

# Remove BOSH CLI cached files
rm -rf $HOME/.bosh

# Setting up the ip table route would be done here if the container shared
# the same network namespace as the host vm - which it does not.
#
# ip route add 10.144.0.0/16 via "${BOSH_DIRECTOR_IP}"
#
# Hence this is done by a linuxkit pkg named bosh-lite-routing
#
# We trigger running ip route command by creating a file.
touch "${DIRECTOR_DIR}/trigger-route-setup"
#
# We previously polled the BOSH Director IP using curl/wget. This had the
# problem of creating an unbounded number of TCP connections in the VM due to
# bad routing.
#
# This happened because the Director's subnet was not associated with a network
# device causing traffic to be routed outside the vm. Once outside due to
# the Director IP alias on the loopback device and since vpnkit was listening on
# the IP/port, traffic would flow back to the VM. Finally, the
# vpnkit-forwarder in the VM would make the same original request to the BOSH
# Director IP continuing the loop
